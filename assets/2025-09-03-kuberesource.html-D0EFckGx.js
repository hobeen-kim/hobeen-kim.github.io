import{_ as u,c as p,a,b as e,d as c,f as t,r as i,o as d,e as l}from"./app-DrhwENuX.js";const m="/images/2025-09-03-kuberesource/image-20250904205438084.png",k={},b={class:"table-of-contents"};function h(g,s){const r=i("Header"),n=i("router-link"),o=i("Footer");return d(),p("div",null,[a(r),e("nav",b,[e("ul",null,[e("li",null,[a(n,{to:"#모니터링-리소스"},{default:t(()=>s[0]||(s[0]=[l("모니터링 리소스")])),_:1})]),e("li",null,[a(n,{to:"#컨테이너와-파드-사용량-제한-limits-requests"},{default:t(()=>s[1]||(s[1]=[l("컨테이너와 파드 사용량 제한: Limits, requests")])),_:1}),e("ul",null,[e("li",null,[a(n,{to:"#limits-와-requests"},{default:t(()=>s[2]||(s[2]=[l("Limits 와 Requests")])),_:1})])])]),e("li",null,[a(n,{to:"#qos-클래스"},{default:t(()=>s[3]||(s[3]=[l("QoS 클래스")])),_:1}),e("ul",null,[e("li",null,[a(n,{to:"#guaranteed-클래스"},{default:t(()=>s[4]||(s[4]=[l("Guaranteed 클래스")])),_:1})]),e("li",null,[a(n,{to:"#besteffort-클래스"},{default:t(()=>s[5]||(s[5]=[l("BestEffort 클래스")])),_:1})]),e("li",null,[a(n,{to:"#burstable-클래스"},{default:t(()=>s[6]||(s[6]=[l("Burstable 클래스")])),_:1})]),e("li",null,[a(n,{to:"#qos-의-종료-순서"},{default:t(()=>s[7]||(s[7]=[l("QoS 의 종료 순서")])),_:1})])])]),e("li",null,[a(n,{to:"#resourcequata-와-limitrange"},{default:t(()=>s[8]||(s[8]=[l("ResourceQuata 와 LimitRange")])),_:1})]),e("li",null,[a(n,{to:"#내-선택은"},{default:t(()=>s[9]||(s[9]=[l("내 선택은")])),_:1})])])]),s[10]||(s[10]=c(`<p>쿠버네티스로 배포된 서버를 운영하기 위한 마지막 단계 중 하나는 실제 부하를 테스트해보는 것이다. 테스트를 하기 전에 우선 파드별로 할당된 리소스가 적절한지 확인하려고 했다. 그리고 테스트 이후에 다시 평가할 예정이다.</p><p>파드별로 cpu, memory 리소스가 필요한만큼 제대로 분배되지 못하면 노드의 리소스는 남음에도 파드의 리소스 제한으로 인해 남은 노드의 리소스를 모두 못쓰거나, 과도한 오버커밋때문에 중요한 파드가 꺼질 수도 있다.</p><h1 id="모니터링-리소스" tabindex="-1"><a class="header-anchor" href="#모니터링-리소스"><span>모니터링 리소스</span></a></h1><p>현재 모니터링 툴로 prometheus, grafana, Loki 를 사용하고 있다. 프로메테우스 스택은 오픈 소스라서 비용이 들지 않고 간단하게 배포할 수 있지만, 반대로 직접 서버를 관리해야 해서 리소스 관리에 신경써야 한다.</p><p>현재 프로젝트에서 c6g.xlarge 를 예산 상 3대 운용하려고 계획하고 있는데 모니터링 툴이 차지하는 메모리가 너무 컸다. 특히나 부하 상황에서 서버의 메모리가 많이 필요할 때 모니터링 툴에 의해 리소스가 제한되거나, 또는 메모리 경합으로 서버가 꺼지는 상황을 막아야겠다고 생각했다.</p><p>이 부분을 해결하기 위해 프로메테우스 스택의 리소스 requests, limits 를 설정해서 모니터링 리소스를 제한하려고 했으나 helm chart 에는 해당 설정이 없었다. 따라서 쿠버네티스의 Limits, Requests 를 다시 정리한 뒤에 <strong>ResourceQuata</strong> 와 <strong>LimitRange</strong> 를 사용해서 리소스를 제한하고자 했다.</p><h1 id="컨테이너와-파드-사용량-제한-limits-requests" tabindex="-1"><a class="header-anchor" href="#컨테이너와-파드-사용량-제한-limits-requests"><span>컨테이너와 파드 사용량 제한: Limits, requests</span></a></h1><h2 id="limits-와-requests" tabindex="-1"><a class="header-anchor" href="#limits-와-requests"><span>Limits 와 Requests</span></a></h2><p>쿠버네티스는 limits 키워드를 통해 자원 사용량의 최대치를 제한시키고, requests 로 자원의 최소치를 보장한다.</p><div class="language-yaml line-numbers-mode" data-highlighter="prismjs" data-ext="yml" data-title="yml"><pre><code><span class="line"><span class="token key atrule">apiVerision</span><span class="token punctuation">:</span> v1</span>
<span class="line"><span class="token key atrule">kind</span><span class="token punctuation">:</span> Pod</span>
<span class="line"><span class="token key atrule">metadata</span><span class="token punctuation">:</span></span>
<span class="line">	<span class="token key atrule">name</span><span class="token punctuation">:</span> limited<span class="token punctuation">-</span>pod</span>
<span class="line"><span class="token key atrule">spec</span><span class="token punctuation">:</span></span>
<span class="line">	<span class="token key atrule">containers</span><span class="token punctuation">:</span></span>
<span class="line">	<span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> nginx</span>
<span class="line">	  <span class="token key atrule">image</span><span class="token punctuation">:</span> nginx</span>
<span class="line">	  <span class="token key atrule">resources</span><span class="token punctuation">:</span></span>
<span class="line">	    <span class="token key atrule">limits</span><span class="token punctuation">:</span></span>
<span class="line">	      <span class="token key atrule">cpu</span><span class="token punctuation">:</span> 1000m</span>
<span class="line">	      <span class="token key atrule">memory</span><span class="token punctuation">:</span> 512MiB</span>
<span class="line">      <span class="token key atrule">requests</span><span class="token punctuation">:</span></span>
<span class="line">	      <span class="token key atrule">cpu</span><span class="token punctuation">:</span> 100m</span>
<span class="line">	      <span class="token key atrule">memory</span><span class="token punctuation">:</span> 128MiB</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>쿠버네티스는 컨테이너의 자원활용률을 높이기 위해 <strong>오버커밋</strong>을 사용한다. 오버커밋이란 한정된 컴퓨팅 자원을 효율적으로 사용하기 위한 방법으로 사용할 수 있는 자원보다 더 많은 양을 VM 또는 컨테이너에게 할당하는 것이다.</p><p>예를 들어 아래처럼 메모리가 1GiB 인 노드에 각각 requests, limits 가 400MiB, 700MiB 인 컨테이너(파드)가 2개 있다고 가정하자.</p><p><img src="`+m+'" alt="image-20250904205438084"></p><p>물리적인 메모리는 1GiB 지만 A, B 각각에게 할당된 메모리의 합은 대략 <strong>1.4GiB</strong> 이다. 이처럼 유휴 자원이 남을 때 오버커밋을 통해 자원이 유동적으로 분배된다.</p><p>하지만 위와 같은 상황에서 A 컨테이너가 자신의 request 만큼 사용해야 한다면(자원의 경합) 어떤 일이 벌어질까?</p><h1 id="qos-클래스" tabindex="-1"><a class="header-anchor" href="#qos-클래스"><span>QoS 클래스</span></a></h1><p>메모리는 압축불가능한(Incompressible) 자원으로 취급되기 때문에 메모리 사용량에 경합이 발생하면 우선순위가 낮은 파드를 강제 종료시킨다.</p><p>여기서 중요한 부분은 **&#39;메모리 자원 부족 시 어떤 파드가 먼저 종료돼야 하는가&#39;**이다. 쿠버네티스는 Limits 와 Requests 값에 따라 우선순위를 정하는데 특히 3가지 종류의 QoS (Quality Of Service) 클래스가 파드별로 설정되어 활용된다.</p><blockquote><p>쿠버네티스의 파드 Eviction 과 노드의 oom_killer 의 동작은 다르다. 파드 Eviction 시 QoS 는 고려되지 않는다. 이 부분은 다른 글에서 확인해보겠다.</p></blockquote><h2 id="guaranteed-클래스" tabindex="-1"><a class="header-anchor" href="#guaranteed-클래스"><span>Guaranteed 클래스</span></a></h2><h2 id="besteffort-클래스" tabindex="-1"><a class="header-anchor" href="#besteffort-클래스"><span>BestEffort 클래스</span></a></h2><h2 id="burstable-클래스" tabindex="-1"><a class="header-anchor" href="#burstable-클래스"><span>Burstable 클래스</span></a></h2><h2 id="qos-의-종료-순서" tabindex="-1"><a class="header-anchor" href="#qos-의-종료-순서"><span>QoS 의 종료 순서</span></a></h2><h1 id="resourcequata-와-limitrange" tabindex="-1"><a class="header-anchor" href="#resourcequata-와-limitrange"><span>ResourceQuata 와 LimitRange</span></a></h1><h1 id="내-선택은" tabindex="-1"><a class="header-anchor" href="#내-선택은"><span>내 선택은</span></a></h1><p>내 선택은 &quot;아무 것도 적용하지 않는다.&quot; 였다 (!)</p><ol><li>프로메테우스가 부하를 많이 받고 메모리를 많이 사용할 일이 없다. 메모리를 많이 쓰는 loki 의 memcached 는 메모리 limit 이 설정되어있다.</li><li>따라서 서버 파드의 requests, limits 만 잘 설정하면 오버커밋에 의한 파드 축출이나 oom_kill 이 발생하지 않을거라 생각했다.</li><li>그리고 당연히 파드 축출 전에 오토스케일링이 되어야 한다.</li><li>메모리 사용량은 그라파나에서 확인이 가능하다. 충분한 운영을 한 뒤 실제 사용량을 보고 결정해도 늦지 않다.</li></ol><p>오히려 ResourceQuata 나 LimitRange 를 설정하면 복잡성만 늘어난다. LimitRange 는 namesapce 의 리소스인데, 모든 파드에 대해 일괄적으로 적용된다. 따라서 파드별 특성을 고려해 default 값을 적용할 수가 없다.</p><p>또한 ResourceQuata 는 환경이 커졌을 때 문제가 발생할 수 있다고 생각했다. 노드가 늘어날 수록 데몬셋이 사용하는 리소스(node exporter 등)가 커지는데, ResourceQuata 로 namespace 를 제한해버린다면, 노드가 100개로 늘어났을 때 데몬셋 리소스도 100개 필요하므로 ResourceQuata 에 의해 생성되지 않을 수도 있겠다고 생각했다.</p><p>요컨대, 현재 단계에서 굳이 <strong>&quot;복잡성을 늘리지 말자&quot;</strong> 라고 생각했다.</p>',30)),a(o)])}const f=u(k,[["render",h],["__file","2025-09-03-kuberesource.html.vue"]]),q=JSON.parse('{"path":"/posts/infra/2025-09-03-kuberesource.html","title":"쿠버네티스 운영 환경 준비 하기 - 파드 리소스 할당","lang":"en-US","frontmatter":{"title":"쿠버네티스 운영 환경 준비 하기 - 파드 리소스 할당","date":"2025-09-04T00:00:00.000Z","tags":["kubenetes","resources","pod"],"description":"파드 리소스 사용량 제한 확인하기"},"headers":[{"level":1,"title":"모니터링 리소스","slug":"모니터링-리소스","link":"#모니터링-리소스","children":[]},{"level":1,"title":"컨테이너와 파드 사용량 제한: Limits, requests","slug":"컨테이너와-파드-사용량-제한-limits-requests","link":"#컨테이너와-파드-사용량-제한-limits-requests","children":[{"level":2,"title":"Limits 와 Requests","slug":"limits-와-requests","link":"#limits-와-requests","children":[]}]},{"level":1,"title":"QoS 클래스","slug":"qos-클래스","link":"#qos-클래스","children":[{"level":2,"title":"Guaranteed 클래스","slug":"guaranteed-클래스","link":"#guaranteed-클래스","children":[]},{"level":2,"title":"BestEffort 클래스","slug":"besteffort-클래스","link":"#besteffort-클래스","children":[]},{"level":2,"title":"Burstable 클래스","slug":"burstable-클래스","link":"#burstable-클래스","children":[]},{"level":2,"title":"QoS 의 종료 순서","slug":"qos-의-종료-순서","link":"#qos-의-종료-순서","children":[]}]},{"level":1,"title":"ResourceQuata 와 LimitRange","slug":"resourcequata-와-limitrange","link":"#resourcequata-와-limitrange","children":[]},{"level":1,"title":"내 선택은","slug":"내-선택은","link":"#내-선택은","children":[]}],"git":{},"filePathRelative":"_posts/infra/2025-09-03-kuberesource.md"}');export{f as comp,q as data};
